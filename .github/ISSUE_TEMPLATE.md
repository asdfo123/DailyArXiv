---
title: Latest 15 Papers - March 05, 2025
labels: documentation
---
**Please check the [Github](https://github.com/zezhishao/MTS_Daily_ArXiv) page for a better reading experience and more papers.**

## Knowledge Editing
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Can Knowledge Editing Really Correct Hallucinations?](http://arxiv.org/abs/2410.16251v3)** | 2025-03-03 | <details><summary>ICLR ...</summary><p>ICLR 2025. Main paper: 10 pages; total: 34 pages (including appendix). The first two authors contributed equally to this work. Code, data, results, and additional resources are available on the project website: https://llm-editing.github.io</p></details> |
| **[MMKE-Bench: A Multimodal Editing Benchmark for Diverse Visual Knowledge](http://arxiv.org/abs/2502.19870v2)** | 2025-03-01 | <details><summary>Accep...</summary><p>Accept to ICLR2025. Project Page: https://mmke-bench-iclr.github.io/</p></details> |
| **[Relation Also Knows: Rethinking the Recall and Editing of Factual Associations in Auto-Regressive Transformer Language Models](http://arxiv.org/abs/2408.15091v3)** | 2025-02-27 | Accepted by AAAI25 |
| **[GeoEdit: Geometric Knowledge Editing for Large Language Models](http://arxiv.org/abs/2502.19953v1)** | 2025-02-27 |  |
| **[K-Edit: Language Model Editing with Contextual Knowledge Awareness](http://arxiv.org/abs/2502.10626v2)** | 2025-02-27 |  |
| **[Norm Growth and Stability Challenges in Localized Sequential Knowledge Editing](http://arxiv.org/abs/2502.19416v1)** | 2025-02-26 | <details><summary>Accep...</summary><p>Accepted for Oral Presentation at KnowFM @ AAAI 2025. arXiv admin note: text overlap with arXiv:2502.01636</p></details> |
| **[Knowledge in Superposition: Unveiling the Failures of Lifelong Knowledge Editing for Large Language Models](http://arxiv.org/abs/2408.07413v3)** | 2025-02-26 | <details><summary>To be...</summary><p>To be published in AAAI 2025 (Oral)</p></details> |
| **[From Text to Emoji: How PEFT-Driven Personality Manipulation Unleashes the Emoji Potential in LLMs](http://arxiv.org/abs/2409.10245v4)** | 2025-02-25 | <details><summary>Findi...</summary><p>Findings paper of NAACL 2025 and NeurIPS 2024 Workshop on Behavioral Machine Learning</p></details> |
| **[Everything is Editable: Extend Knowledge Editing to Unstructured Data in Large Language Models](http://arxiv.org/abs/2405.15349v3)** | 2025-02-25 | ICLR 2025 |
| **[CKnowEdit: A New Chinese Knowledge Editing Dataset for Linguistics, Facts, and Logic Error Correction in LLMs](http://arxiv.org/abs/2409.05806v3)** | 2025-02-24 | <details><summary>Ongoi...</summary><p>Ongoing work; project website is available at https://zjunlp.github.io/project/CKnowEdit code and dataset are available at https://github.com/zjunlp/EasyEdit</p></details> |
| **[CollabEdit: Towards Non-destructive Collaborative Knowledge Editing](http://arxiv.org/abs/2410.09508v4)** | 2025-02-22 | <details><summary>20 pa...</summary><p>20 pages, 11 figures. Published as a conference paper at ICLR 2025. Code at https://github.com/LINs-lab/CollabEdit</p></details> |
| **[FLEKE: Federated Locate-then-Edit Knowledge Editing](http://arxiv.org/abs/2502.15677v1)** | 2025-02-21 |  |
| **[Revealing and Mitigating Over-Attention in Knowledge Editing](http://arxiv.org/abs/2502.14838v1)** | 2025-02-20 |  |
| **[Edit Once, Update Everywhere: A Simple Framework for Cross-Lingual Knowledge Synchronization in LLMs](http://arxiv.org/abs/2502.14645v1)** | 2025-02-20 |  |
| **[BMIKE-53: Investigating Cross-Lingual Knowledge Editing with In-Context Learning](http://arxiv.org/abs/2406.17764v2)** | 2025-02-19 | 18 pages, 10 figures |

## Model Editing
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Perturbation-Restrained Sequential Model Editing](http://arxiv.org/abs/2405.16821v3)** | 2025-03-03 | <details><summary>Accep...</summary><p>Accepted by ICLR 2025</p></details> |
| **[Model Editing as a Robust and Denoised variant of DPO: A Case Study on Toxicity](http://arxiv.org/abs/2405.13967v5)** | 2025-03-01 | <details><summary>Accep...</summary><p>Accepted to ICLR 2025</p></details> |
| **[GeoEdit: Geometric Knowledge Editing for Large Language Models](http://arxiv.org/abs/2502.19953v1)** | 2025-02-27 |  |
| **[K-Edit: Language Model Editing with Contextual Knowledge Awareness](http://arxiv.org/abs/2502.10626v2)** | 2025-02-27 |  |
| **[A Causal Lens for Evaluating Faithfulness Metrics](http://arxiv.org/abs/2502.18848v1)** | 2025-02-26 | <details><summary>18 pa...</summary><p>18 pages, 18 figures, 6 tables</p></details> |
| **[The Mirage of Model Editing: Revisiting Evaluation in the Wild](http://arxiv.org/abs/2502.11177v3)** | 2025-02-23 |  |
| **[Self-Updatable Large Language Models by Integrating Context into Model Parameters](http://arxiv.org/abs/2410.00487v2)** | 2025-02-21 |  |
| **[CoME: An Unlearning-based Approach to Conflict-free Model Editing](http://arxiv.org/abs/2502.15826v1)** | 2025-02-20 | <details><summary>Accep...</summary><p>Accepted to NAACL 2025 main conference</p></details> |
| **[Reinforced Lifelong Editing for Language Models](http://arxiv.org/abs/2502.05759v2)** | 2025-02-18 |  |
| **[MeMo: Towards Language Models with Associative Memory Mechanisms](http://arxiv.org/abs/2502.12851v1)** | 2025-02-18 |  |
| **[Bring Your Own Knowledge: A Survey of Methods for LLM Knowledge Expansion](http://arxiv.org/abs/2502.12598v1)** | 2025-02-18 |  |
| **[DELMAN: Dynamic Defense Against Large Language Model Jailbreaking with Model Editing](http://arxiv.org/abs/2502.11647v1)** | 2025-02-17 |  |
| **[Breaking Boundaries: Investigating the Effects of Model Editing on Cross-linguistic Performance](http://arxiv.org/abs/2406.11139v3)** | 2025-02-17 | <details><summary>Accep...</summary><p>Accepted at NAACL 2025 (Industry track)</p></details> |
| **[SWEA: Updating Factual Knowledge in Large Language Models via Subject Word Embedding Altering](http://arxiv.org/abs/2401.17809v4)** | 2025-02-17 | <details><summary>AAAI2...</summary><p>AAAI25. Our code is available at https://github.com/xpq-tech/SWEA</p></details> |
| **[REVS: Unlearning Sensitive Information in Language Models via Rank Editing in the Vocabulary Space](http://arxiv.org/abs/2406.09325v3)** | 2025-02-16 | 18 pages, 3 figures |

## GUI Agent
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[VEM: Environment-Free Exploration for Training GUI Agent with Value Environment Model](http://arxiv.org/abs/2502.18906v1)** | 2025-02-26 | 20pages,5 figures |
| **[PC-Agent: A Hierarchical Multi-Agent Collaboration Framework for Complex Task Automation on PC](http://arxiv.org/abs/2502.14282v2)** | 2025-02-21 | 14 pages, 7 figures |
| **[WorldGUI: Dynamic Testing for Comprehensive Desktop GUI Automation](http://arxiv.org/abs/2502.08047v2)** | 2025-02-19 | 19 pages, 18 figures |
| **[A3: Android Agent Arena for Mobile GUI Agents](http://arxiv.org/abs/2501.01149v2)** | 2025-02-18 |  |
| **[TRISHUL: Towards Region Identification and Screen Hierarchy Understanding for Large VLM based GUI Agents](http://arxiv.org/abs/2502.08226v2)** | 2025-02-14 | 8 pages 5 figures |
| **[Large Language Model-Brained GUI Agents: A Survey](http://arxiv.org/abs/2411.18279v9)** | 2025-02-14 | <details><summary>The c...</summary><p>The collection of papers reviewed in this survey will be hosted and regularly updated on the GitHub repository: https://github.com/vyokky/LLM-Brained-GUI-Agents-Survey Additionally, a searchable webpage is available at https://aka.ms/gui-agent for easier access and exploration</p></details> |
| **[GUI Agents with Foundation Models: A Comprehensive Survey](http://arxiv.org/abs/2411.04890v2)** | 2025-02-13 |  |
| **[UI-TARS: Pioneering Automated GUI Interaction with Native Agents](http://arxiv.org/abs/2501.12326v1)** | 2025-01-21 |  |
| **[InfiGUIAgent: A Multimodal Generalist GUI Agent with Native Reasoning and Reflection](http://arxiv.org/abs/2501.04575v1)** | 2025-01-08 | <details><summary>14 pa...</summary><p>14 pages, 7 figures, work in progress</p></details> |
| **[OS-Genesis: Automating GUI Agent Trajectory Construction via Reverse Task Synthesis](http://arxiv.org/abs/2412.19723v1)** | 2024-12-27 | Work in progress |
| **[CogAgent: A Visual Language Model for GUI Agents](http://arxiv.org/abs/2312.08914v3)** | 2024-12-27 | <details><summary>CVPR ...</summary><p>CVPR 2024 (Highlight), 27 pages, 19 figures</p></details> |
| **[AutoDroid-V2: Boosting SLM-based GUI Agents via Code Generation](http://arxiv.org/abs/2412.18116v2)** | 2024-12-26 | 15 pages, 5 figures |
| **[GUI Testing Arena: A Unified Benchmark for Advancing Autonomous GUI Testing Agent](http://arxiv.org/abs/2412.18426v1)** | 2024-12-24 |  |
| **[GUI Agents: A Survey](http://arxiv.org/abs/2412.13501v1)** | 2024-12-18 |  |
| **[AgentTrek: Agent Trajectory Synthesis via Guiding Replay with Web Tutorials](http://arxiv.org/abs/2412.09605v2)** | 2025-03-03 | <details><summary>ICLR2...</summary><p>ICLR2025 Spotlight https://agenttrek.github.io</p></details> |

## Efficient LLM
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[MiLoRA: Harnessing Minor Singular Components for Parameter-Efficient LLM Finetuning](http://arxiv.org/abs/2406.09044v3)** | 2025-03-02 | <details><summary>This ...</summary><p>This paper has been accepted at NAACL 2025. Code is available at: https://github.com/sufenlp/MiLoRA</p></details> |
| **[ThinK: Thinner Key Cache by Query-Driven Pruning](http://arxiv.org/abs/2407.21018v3)** | 2025-02-27 | <details><summary>ICLR ...</summary><p>ICLR 2025 (Spotlight)</p></details> |
| **[Progressive Mixed-Precision Decoding for Efficient LLM Inference](http://arxiv.org/abs/2410.13461v2)** | 2025-02-27 |  |
| **[Dynamic Parallel Tree Search for Efficient LLM Reasoning](http://arxiv.org/abs/2502.16235v2)** | 2025-02-27 | 17 pages, 11 figures |
| **[Beyond Linear Approximations: A Novel Pruning Approach for Attention Matrix](http://arxiv.org/abs/2410.11261v2)** | 2025-02-26 | ICLR 2025 |
| **[Evidence-Driven Marker Extraction for Social Media Suicide Risk Detection](http://arxiv.org/abs/2502.18823v1)** | 2025-02-26 |  |
| **[AttentionPredictor: Temporal Pattern Matters for Efficient LLM Inference](http://arxiv.org/abs/2502.04077v2)** | 2025-02-26 |  |
| **[Rethinking Layer Removal: A Hybrid Pruning Framework Combining Layer Removal and Singular Value Selection for Efficient LLM Compression](http://arxiv.org/abs/2501.00339v2)** | 2025-02-25 | 16 pages, 5 figures |
| **[Sketch to Adapt: Fine-Tunable Sketches for Efficient LLM Adaptation](http://arxiv.org/abs/2410.06364v2)** | 2025-02-25 |  |
| **[Make LLM Inference Affordable to Everyone: Augmenting GPU Memory with NDP-DIMM](http://arxiv.org/abs/2502.16963v1)** | 2025-02-24 | <details><summary>15 pa...</summary><p>15 pages, 17 figures, accepted by HPCA 2025</p></details> |
| **[TerEffic: Highly Efficient Ternary LLM Inference on FPGA](http://arxiv.org/abs/2502.16473v1)** | 2025-02-23 |  |
| **[Efficient AI in Practice: Training and Deployment of Efficient LLMs for Industry Applications](http://arxiv.org/abs/2502.14305v1)** | 2025-02-20 |  |
| **[VilBias: A Study of Bias Detection through Linguistic and Visual Cues , presenting Annotation Strategies, Evaluation, and Key Challenges](http://arxiv.org/abs/2412.17052v3)** | 2025-02-18 | Under review |
| **[SEFL: Harnessing Large Language Model Agents to Improve Educational Feedback Systems](http://arxiv.org/abs/2502.12927v1)** | 2025-02-18 |  |
| **[HeadInfer: Memory-Efficient LLM Inference by Head-wise Offloading](http://arxiv.org/abs/2502.12574v1)** | 2025-02-18 |  |

